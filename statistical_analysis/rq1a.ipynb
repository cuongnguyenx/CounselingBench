{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: statsmodels in /home/cnguyen319/.local/lib/python3.10/site-packages (0.14.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/cnguyen319/.local/lib/python3.10/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/cnguyen319/.local/lib/python3.10/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/cnguyen319/.local/lib/python3.10/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/cnguyen319/.local/lib/python3.10/site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/cnguyen319/.local/lib/python3.10/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cnguyen319/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/cnguyen319/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621\n"
     ]
    }
   ],
   "source": [
    "df_gold = pd.read_csv('../data/mct_combined_v3.csv')\n",
    "categories = ['Overall'] + list(set(df_gold['question_category']))\n",
    "# dfx = pd.read_csv('../data/tiebreaking_needed.csv')\n",
    "# df_gold = df_gold[~df_gold['Question'].isin(dfx['Question_x'])]\n",
    "print(df_gold.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'counseling skills and interventions': 600,\n",
       "         'intake, assessment, and diagnosis': 466,\n",
       "         'professional practice and ethics': 275,\n",
       "         'treatment planning': 254,\n",
       "         'core counseling attributes': 23,\n",
       "         nan: 2,\n",
       "         'counseling': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_gold['question_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CounselingQA_metrics_combined.csv')\n",
    "# dx = df[['setting', 'Accuracy_Overall', 'F1_Overall', 'Precision_Overall', 'Recall_Overall']]\n",
    "# dx = dx[dx['setting'].str.contains('zero-shot_None_0')]\n",
    "# dx.to_csv('./table1a.csv', index=False)\n",
    "examined_models = ['Meta-Llama-3-70B-Instruct_few-shot_None_3', 'Llama3-Med42-70B_few-shot_None_3', 'Llama3-OpenBioLLM-70B_few-shot_None_3', 'counselingQA-gpt4o_zero-shot_None_0']\n",
    "df = df[df['setting'].isin(examined_models)]\n",
    "df.to_csv('./table2.csv', index=False)\n",
    "# df = df[(df['setting'].str.contains('zero-shot_None_0')) | (df['setting'].str.contains('few-shot_None_3')) | (df['setting'].str.contains('zero-shot_sc_0')) | (df['setting'].str.contains('few-shot_sc_3')) | (df['setting'].str.contains('few-shot-cot_None_3'))]\n",
    "# df['model_name'] = [x[:x.find('_')] for x in df['setting']]\n",
    "# dfx = df[df['Accuracy_Overall'] > 0.6]\n",
    "# df = df[df['model_name'].isin(dfx['model_name'])]\n",
    "# df1 = df[df['setting'].str.contains('zero-shot_None_0')].sort_values(by=['setting'])\n",
    "# df2 = df[df['setting'].str.contains('zero-shot_sc_0')].sort_values(by=['setting'])\n",
    "# df3 = df[df['setting'].str.contains('few-shot_None_3')].sort_values(by=['setting'])\n",
    "# df4 = df[df['setting'].str.contains('few-shot_sc_3')].sort_values(by=['setting'])\n",
    "# df5 = df[df['setting'].str.contains('few-shot-cot_None_3')].sort_values(by=['setting'])\n",
    "# df = pd.concat([df1, df2, df3, df4, df5], axis=False)\n",
    "# df.to_csv('./table3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asclepius-13B_few-shot_sc_1\n",
      "medalpaca-7b_few-shot_None_1\n",
      "Llama-2-13b-hf_few-shot_None_1\n",
      "Asclepius-13B_few-shot_sc_3\n",
      "BioMedGPT-LM-7B_few-shot-cot_None_3\n",
      "Llama3-Med42-8B_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_sc_1\n",
      "Mistral-7B-Instruct-v0.3_few-shot-cot_None_1\n",
      "BioMedGPT-LM-7B_few-shot_None_3\n",
      "Llama3-Med42-70B_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_few-shot_sc_3\n",
      "meditron-70b_few-shot-cot_None_1\n",
      "Asclepius-7B_few-shot-cot_None_3\n",
      "med42-70b_few-shot_None_3\n",
      "Llama3-Med42-8B_few-shot_None_5\n",
      "ClinicalCamel-70B_few-shot-cot_None_3\n",
      "Llama3-Med42-70B_few-shot_sc_1\n",
      "Llama-2-70b-hf_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_3\n",
      "ClinicalCamel-70B_few-shot_None_3\n",
      "Llama-2-70b-hf_few-shot_None_3\n",
      "ClinicalCamel-70B_zero-shot_None_0\n",
      "meditron-70b_zero-shot_sc_0\n",
      "meditron-7b_few-shot_sc_1\n",
      "Llama-2-70b-hf_zero-shot_None_0\n",
      "BioMedGPT-LM-7B_few-shot_sc_1\n",
      "BioMedGPT-LM-7B_few-shot_sc_5\n",
      "Llama-2-13b-chat-hf_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot_sc_5\n",
      "medalpaca-7b_zero-shot_None_0\n",
      "llama-2-7b-chat-hf_few-shot_None_3\n",
      "BioMedGPT-LM-7B_zero-shot_sc_0\n",
      "medalpaca-7b_few-shot_None_3\n",
      "Meta-Llama-3-70B-Instruct_few-shot_None_1\n",
      "Llama-2-7b-hf_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot-cot_None_3\n",
      "llama-2-7b-chat-hf_few-shot-cot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot-cot_None_3\n",
      "Llama-2-13b-chat-hf_few-shot_None_3\n",
      "Llama3-Med42-70B_few-shot_None_1\n",
      "meditron-70b_zero-shot_None_0\n",
      "meditron-7b_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_3\n",
      "llama-2-7b-chat-hf_few-shot_sc_5\n",
      "Llama-2-7b-hf_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_zero-shot_sc_0\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_1\n",
      "Llama3-Med42-8B_zero-shot_None_0\n",
      "med42-70b_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_zero-shot_None_0\n",
      "MentaLLaMA-chat-13B_few-shot_None_1\n",
      "counselingQA-gpt4o_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot_None_5\n",
      "Asclepius-Llama3-8B_few-shot_sc_1\n",
      "meditron-7b_zero-shot_sc_0\n",
      "MentaLLaMA-chat-13B_few-shot_None_5\n",
      "Asclepius-7B_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_sc_5\n",
      "ClinicalCamel-70B_few-shot_sc_3\n",
      "Llama-2-13b-hf_zero-shot_sc_0\n",
      "Llama3-OpenBioLLM-8B_zero-shot_None_0\n",
      "Llama-2-70b-hf_zero-shot_sc_0\n",
      "llama-2-7b-chat-hf_zero-shot_None_0\n",
      "Asclepius-7B_few-shot_None_1\n",
      "Llama-2-13b-chat-hf_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_sc_5\n",
      "Meta-Llama-3-70B-Instruct_few-shot-cot_None_1\n",
      "Llama-2-7b-hf_few-shot_sc_5\n",
      "Llama-2-70b-hf_few-shot-cot_None_3\n",
      "BioMedGPT-LM-7B_few-shot_None_5\n",
      "meditron-7b_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot_sc_1\n",
      "meditron-7b_few-shot_None_5\n",
      "Llama3-Med42-8B_zero-shot_sc_0\n",
      "Llama-2-13b-hf_few-shot-cot_None_1\n",
      "Llama-2-7b-hf_few-shot_sc_1\n",
      "ClinicalCamel-70B_zero-shot_sc_0\n",
      "Meta-Llama-3-70B-Instruct_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_None_1\n",
      "Llama-2-13b-hf_zero-shot_None_0\n",
      "Llama-2-13b-chat-hf_zero-shot_None_0\n",
      "Asclepius-13B_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot-cot_None_3\n",
      "medalpaca-13b_few-shot_sc_1\n",
      "med42-70b_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_zero-shot_sc_0\n",
      "Llama-2-13b-chat-hf_few-shot_None_1\n",
      "medalpaca-13b_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_sc_5\n",
      "ClinicalCamel-70B_few-shot_None_1\n",
      "Llama-2-70b-chat-hf_few-shot_sc_1\n",
      "med42-70b_few-shot_sc_5\n",
      "medalpaca-13b_zero-shot_sc_0\n",
      "Llama-2-70b-chat-hf_few-shot_None_5\n",
      "Meta-Llama-3-70B-Instruct_few-shot_None_3\n",
      "med42-70b_zero-shot_None_0\n",
      "med42-70b_zero-shot_sc_0\n",
      "Mistral-7B-Instruct-v0.3_zero-shot_None_0\n",
      "Llama-2-70b-chat-hf_few-shot_sc_5\n",
      "Llama-2-13b-hf_few-shot_None_5\n",
      "llama-2-7b-chat-hf_few-shot_None_5\n",
      "Asclepius-Llama3-8B_few-shot_None_3\n",
      "Asclepius-13B_few-shot-cot_None_3\n",
      "ClinicalCamel-70B_few-shot_None_5\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_sc_1\n",
      "Llama-2-13b-chat-hf_few-shot-cot_None_1\n",
      "Asclepius-7B_few-shot_None_3\n",
      "Asclepius-Llama3-8B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_zero-shot_sc_0\n",
      "counselingQA-gpt4o_few-shot-cot_None_1\n",
      "medalpaca-7b_few-shot-cot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot-cot_None_3\n",
      "medalpaca-7b_zero-shot_sc_0\n",
      "counselingQA-gpt4o_few-shot_None_1\n",
      "MentaLLaMA-chat-13B_few-shot_None_3\n",
      "Llama-2-7b-hf_zero-shot_sc_0\n",
      "Asclepius-Llama3-8B_few-shot-cot_None_3\n",
      "Asclepius-7B_few-shot_None_5\n",
      "meditron-70b_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_zero-shot_None_0\n",
      "Llama-2-70b-chat-hf_zero-shot_sc_0\n",
      "Llama-2-7b-hf_few-shot-cot_None_1\n",
      "Llama3-OpenBioLLM-8B_zero-shot_sc_0\n",
      "Asclepius-13B_few-shot_None_1\n",
      "medalpaca-7b_few-shot_None_5\n",
      "Asclepius-7B_zero-shot_sc_0\n",
      "Asclepius-7B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_None_5\n",
      "llama-2-7b-chat-hf_zero-shot_sc_0\n",
      "medalpaca-7b_few-shot_sc_5\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_5\n",
      "medalpaca-13b_few-shot_None_3\n",
      "Llama3-Med42-70B_zero-shot_None_0\n",
      "Llama-2-13b-hf_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot_sc_5\n",
      "meditron-70b_few-shot_None_5\n",
      "Asclepius-13B_few-shot_sc_5\n",
      "Llama3-Med42-8B_few-shot-cot_None_3\n",
      "Llama-2-13b-chat-hf_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot_sc_1\n",
      "meditron-7b_zero-shot_None_0\n",
      "Llama3-Med42-70B_few-shot-cot_None_3\n",
      "Llama-2-70b-chat-hf_few-shot-cot_None_1\n",
      "Llama-2-70b-hf_few-shot_sc_1\n",
      "meditron-70b_few-shot_sc_1\n",
      "Llama-2-13b-hf_few-shot_sc_1\n",
      "Llama-2-70b-chat-hf_few-shot_None_3\n",
      "ClinicalCamel-70B_few-shot_sc_5\n",
      "medalpaca-13b_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_sc_3\n",
      "Llama3-Med42-70B_zero-shot_sc_0\n",
      "llama-2-7b-chat-hf_few-shot_None_1\n",
      "med42-70b_few-shot_None_1\n",
      "ClinicalCamel-70B_few-shot_sc_1\n",
      "Llama-2-13b-chat-hf_few-shot_sc_1\n",
      "Llama-2-70b-chat-hf_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_1\n",
      "Llama-2-70b-chat-hf_zero-shot_None_0\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_5\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_3\n",
      "medalpaca-7b_few-shot_sc_1\n",
      "meditron-70b_few-shot_None_1\n",
      "Asclepius-7B_few-shot_sc_1\n",
      "meditron-70b_few-shot_sc_5\n",
      "Asclepius-13B_few-shot_None_3\n",
      "llama-2-7b-chat-hf_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot_sc_5\n",
      "Llama-2-7b-hf_few-shot_None_3\n",
      "Llama-2-7b-hf_few-shot_None_1\n",
      "Asclepius-13B_zero-shot_None_0\n",
      "meditron-7b_few-shot_sc_5\n",
      "Llama-2-13b-hf_few-shot_sc_5\n",
      "Llama3-Med42-70B_few-shot_None_3\n"
     ]
    }
   ],
   "source": [
    "for r in df['setting']:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MentaLLaMA-chat-13B', 'counselingQA-gpt4o', 'Llama-2-13b-hf', 'Llama-2-13b-chat-hf', 'Llama3-OpenBioLLM-70B', 'Llama3-Med42-70B', 'llama-2-7b-chat-hf', 'medalpaca-7b', 'Mistral-7B-Instruct-v0.3', 'Asclepius-Llama3-8B', 'Llama-2-70b-hf', 'Asclepius-7B', 'BioMedGPT-LM-7B', 'ClinicalCamel-70B', 'med42-70b', 'medalpaca-13b', 'Llama-2-70b-chat-hf', 'Asclepius-13B', 'Llama3-OpenBioLLM-8B', 'meditron-7b', 'Llama3-Med42-8B', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-70B-Instruct', 'Llama-2-7b-hf', 'meditron-70b'}\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for row in df.iterrows():\n",
    "    setting = row[1]['setting']\n",
    "    model_list.append(setting[:setting.find('_')])\n",
    "model_set = set(model_list)\n",
    "print(model_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asclepius-13B_few-shot_sc_1\n",
      "medalpaca-7b_few-shot_None_1\n",
      "Llama-2-13b-hf_few-shot_None_1\n",
      "Asclepius-13B_few-shot_sc_3\n",
      "BioMedGPT-LM-7B_few-shot-cot_None_3\n",
      "Llama3-Med42-8B_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_sc_1\n",
      "Mistral-7B-Instruct-v0.3_few-shot-cot_None_1\n",
      "BioMedGPT-LM-7B_few-shot_None_3\n",
      "Llama3-Med42-70B_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_few-shot_sc_3\n",
      "meditron-70b_few-shot-cot_None_1\n",
      "Asclepius-7B_few-shot-cot_None_3\n",
      "med42-70b_few-shot_None_3\n",
      "Llama3-Med42-8B_few-shot_None_5\n",
      "ClinicalCamel-70B_few-shot-cot_None_3\n",
      "Llama3-Med42-70B_few-shot_sc_1\n",
      "Llama-2-70b-hf_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_3\n",
      "ClinicalCamel-70B_few-shot_None_3\n",
      "Llama-2-70b-hf_few-shot_None_3\n",
      "ClinicalCamel-70B_zero-shot_None_0\n",
      "meditron-70b_zero-shot_sc_0\n",
      "meditron-7b_few-shot_sc_1\n",
      "Llama-2-70b-hf_zero-shot_None_0\n",
      "BioMedGPT-LM-7B_few-shot_sc_1\n",
      "BioMedGPT-LM-7B_few-shot_sc_5\n",
      "Llama-2-13b-chat-hf_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot_sc_5\n",
      "medalpaca-7b_zero-shot_None_0\n",
      "llama-2-7b-chat-hf_few-shot_None_3\n",
      "BioMedGPT-LM-7B_zero-shot_sc_0\n",
      "medalpaca-7b_few-shot_None_3\n",
      "Meta-Llama-3-70B-Instruct_few-shot_None_1\n",
      "Llama-2-7b-hf_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot-cot_None_3\n",
      "llama-2-7b-chat-hf_few-shot-cot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot-cot_None_3\n",
      "Llama-2-13b-chat-hf_few-shot_None_3\n",
      "Llama3-Med42-70B_few-shot_None_1\n",
      "meditron-70b_zero-shot_None_0\n",
      "meditron-7b_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_3\n",
      "llama-2-7b-chat-hf_few-shot_sc_5\n",
      "Llama-2-7b-hf_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_zero-shot_sc_0\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_1\n",
      "Llama3-Med42-8B_zero-shot_None_0\n",
      "med42-70b_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_zero-shot_None_0\n",
      "MentaLLaMA-chat-13B_few-shot_None_1\n",
      "counselingQA-gpt4o_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot_None_5\n",
      "Asclepius-Llama3-8B_few-shot_sc_1\n",
      "meditron-7b_zero-shot_sc_0\n",
      "MentaLLaMA-chat-13B_few-shot_None_5\n",
      "Asclepius-7B_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_few-shot_None_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_sc_5\n",
      "ClinicalCamel-70B_few-shot_sc_3\n",
      "Llama-2-13b-hf_zero-shot_sc_0\n",
      "Llama3-OpenBioLLM-8B_zero-shot_None_0\n",
      "Llama-2-70b-hf_zero-shot_sc_0\n",
      "llama-2-7b-chat-hf_zero-shot_None_0\n",
      "Asclepius-7B_few-shot_None_1\n",
      "Llama-2-13b-chat-hf_few-shot_sc_5\n",
      "BioMedGPT-LM-7B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_sc_5\n",
      "Meta-Llama-3-70B-Instruct_few-shot-cot_None_1\n",
      "Llama-2-7b-hf_few-shot_sc_5\n",
      "Llama-2-70b-hf_few-shot-cot_None_3\n",
      "BioMedGPT-LM-7B_few-shot_None_5\n",
      "meditron-7b_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot_sc_1\n",
      "meditron-7b_few-shot_None_5\n",
      "Llama3-Med42-8B_zero-shot_sc_0\n",
      "Llama-2-13b-hf_few-shot-cot_None_1\n",
      "Llama-2-7b-hf_few-shot_sc_1\n",
      "ClinicalCamel-70B_zero-shot_sc_0\n",
      "Meta-Llama-3-70B-Instruct_zero-shot_None_0\n",
      "Llama3-Med42-8B_few-shot_None_1\n",
      "Llama-2-13b-hf_zero-shot_None_0\n",
      "Llama-2-13b-chat-hf_zero-shot_None_0\n",
      "Asclepius-13B_zero-shot_sc_0\n",
      "medalpaca-13b_few-shot-cot_None_3\n",
      "medalpaca-13b_few-shot_sc_1\n",
      "med42-70b_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_zero-shot_sc_0\n",
      "Llama-2-13b-chat-hf_few-shot_None_1\n",
      "medalpaca-13b_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_sc_5\n",
      "ClinicalCamel-70B_few-shot_None_1\n",
      "Llama-2-70b-chat-hf_few-shot_sc_1\n",
      "med42-70b_few-shot_sc_5\n",
      "medalpaca-13b_zero-shot_sc_0\n",
      "Llama-2-70b-chat-hf_few-shot_None_5\n",
      "Meta-Llama-3-70B-Instruct_few-shot_None_3\n",
      "med42-70b_zero-shot_None_0\n",
      "med42-70b_zero-shot_sc_0\n",
      "Mistral-7B-Instruct-v0.3_zero-shot_None_0\n",
      "Llama-2-70b-chat-hf_few-shot_sc_5\n",
      "Llama-2-13b-hf_few-shot_None_5\n",
      "llama-2-7b-chat-hf_few-shot_None_5\n",
      "Asclepius-Llama3-8B_few-shot_None_3\n",
      "Asclepius-13B_few-shot-cot_None_3\n",
      "ClinicalCamel-70B_few-shot_None_5\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_sc_1\n",
      "Llama-2-13b-chat-hf_few-shot-cot_None_1\n",
      "Asclepius-7B_few-shot_None_3\n",
      "Asclepius-Llama3-8B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_zero-shot_sc_0\n",
      "counselingQA-gpt4o_few-shot-cot_None_1\n",
      "medalpaca-7b_few-shot-cot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot-cot_None_3\n",
      "medalpaca-7b_zero-shot_sc_0\n",
      "counselingQA-gpt4o_few-shot_None_1\n",
      "MentaLLaMA-chat-13B_few-shot_None_3\n",
      "Llama-2-7b-hf_zero-shot_sc_0\n",
      "Asclepius-Llama3-8B_few-shot-cot_None_3\n",
      "Asclepius-7B_few-shot_None_5\n",
      "meditron-70b_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_zero-shot_None_0\n",
      "Llama-2-70b-chat-hf_zero-shot_sc_0\n",
      "Llama-2-7b-hf_few-shot-cot_None_1\n",
      "Llama3-OpenBioLLM-8B_zero-shot_sc_0\n",
      "Asclepius-13B_few-shot_None_1\n",
      "medalpaca-7b_few-shot_None_5\n",
      "Asclepius-7B_zero-shot_sc_0\n",
      "Asclepius-7B_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_None_5\n",
      "llama-2-7b-chat-hf_zero-shot_sc_0\n",
      "medalpaca-7b_few-shot_sc_5\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_5\n",
      "medalpaca-13b_few-shot_None_3\n",
      "Llama3-Med42-70B_zero-shot_None_0\n",
      "Llama-2-13b-hf_few-shot_None_3\n",
      "Llama3-OpenBioLLM-70B_few-shot_sc_5\n",
      "meditron-70b_few-shot_None_5\n",
      "Asclepius-13B_few-shot_sc_5\n",
      "Llama3-Med42-8B_few-shot-cot_None_3\n",
      "Llama-2-13b-chat-hf_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot_sc_1\n",
      "meditron-7b_zero-shot_None_0\n",
      "Llama3-Med42-70B_few-shot-cot_None_3\n",
      "Llama-2-70b-chat-hf_few-shot-cot_None_1\n",
      "Llama-2-70b-hf_few-shot_sc_1\n",
      "meditron-70b_few-shot_sc_1\n",
      "Llama-2-13b-hf_few-shot_sc_1\n",
      "Llama-2-70b-chat-hf_few-shot_None_3\n",
      "ClinicalCamel-70B_few-shot_sc_5\n",
      "medalpaca-13b_zero-shot_None_0\n",
      "Asclepius-Llama3-8B_few-shot_sc_3\n",
      "Llama3-Med42-70B_zero-shot_sc_0\n",
      "llama-2-7b-chat-hf_few-shot_None_1\n",
      "med42-70b_few-shot_None_1\n",
      "ClinicalCamel-70B_few-shot_sc_1\n",
      "Llama-2-13b-chat-hf_few-shot_sc_1\n",
      "Llama-2-70b-chat-hf_few-shot_None_1\n",
      "Llama3-OpenBioLLM-8B_few-shot_None_1\n",
      "Llama-2-70b-chat-hf_zero-shot_None_0\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_5\n",
      "Llama3-OpenBioLLM-70B_few-shot_None_3\n",
      "medalpaca-7b_few-shot_sc_1\n",
      "meditron-70b_few-shot_None_1\n",
      "Asclepius-7B_few-shot_sc_1\n",
      "meditron-70b_few-shot_sc_5\n",
      "Asclepius-13B_few-shot_None_3\n",
      "llama-2-7b-chat-hf_few-shot_sc_1\n",
      "Meta-Llama-3-8B-Instruct_few-shot_None_5\n",
      "MentaLLaMA-chat-13B_few-shot_sc_5\n",
      "Llama-2-7b-hf_few-shot_None_3\n",
      "Llama-2-7b-hf_few-shot_None_1\n",
      "Asclepius-13B_zero-shot_None_0\n",
      "meditron-7b_few-shot_sc_5\n",
      "Llama-2-13b-hf_few-shot_sc_5\n",
      "Llama3-Med42-70B_few-shot_None_3\n"
     ]
    }
   ],
   "source": [
    "for x in df['setting']:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'meditron-70b_zero-shot_sc_0' in list(df['setting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counselingQA-gpt4o does not have zero-shot, self-consistency results\n",
      "counselingQA-gpt4o does not have few-shot, self-consistency results\n",
      "Mistral-7B-Instruct-v0.3 does not have few-shot results\n",
      "Mistral-7B-Instruct-v0.3 does not have zero-shot, self-consistency results\n",
      "Mistral-7B-Instruct-v0.3 does not have few-shot, self-consistency results\n",
      "med42-70b does not have few-shot, chain-of-thought results\n",
      "meditron-7b does not have few-shot, chain-of-thought results\n",
      "Meta-Llama-3-8B-Instruct does not have few-shot, chain-of-thought results\n",
      "Meta-Llama-3-70B-Instruct does not have zero-shot, self-consistency results\n",
      "Meta-Llama-3-70B-Instruct does not have few-shot, self-consistency results\n"
     ]
    }
   ],
   "source": [
    "# Model check \n",
    "for model in model_set:\n",
    "    # Zero-shot\n",
    "    if f\"{model}_zero-shot_None_0\" not in list(df['setting']):\n",
    "        print(f\"{model} does not have zero-shot results\")\n",
    "    # Zero-shot\n",
    "    if model + '_few-shot_None_1' not in list(df['setting']) and model + '_few-shot_None_3' not in list(df['setting']):\n",
    "        print(f\"{model} does not have few-shot results\")\n",
    "    # Zero-shot\n",
    "    if model + '_zero-shot_sc_0' not in list(df['setting']):\n",
    "        print(f\"{model} does not have zero-shot, self-consistency results\")\n",
    "    # Zero-shot\n",
    "    if model + '_few-shot_sc_1' not in list(df['setting']) and model + '_few-shot_sc_3' not in list(df['setting']):\n",
    "        print(f\"{model} does not have few-shot, self-consistency results\")\n",
    "    # Zero-shot\n",
    "    if f'{model}_few-shot-cot_None_1' not in list(df['setting']) and f'{model}_few-shot-cot_None_3' not in list(df['setting']):\n",
    "        print(f\"{model} does not have few-shot, chain-of-thought results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalist_models = ['llama-2-7b-chat-hf', 'Llama-2-7b-hf', 'Llama-2-13b-hf', 'Llama-2-70b-chat-hf', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-70B-Instruct', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-70B-Instruct', 'Llama-2-13b-chat-hf', 'Llama-2-7b-hf']\n",
    "medical_models = ['BioMedGPT-LM-7B', 'Asclepius-7B', 'Asclepius-13B', 'meditron-70b', 'Llama3-Med42-8B', 'Asclepius-Llama3-8B', 'Llama3-Med42-70B',  'Llama3-OpenBioLLM-8B', 'Llama3-OpenBioLLM-70B', 'MentaLLaMA-chat-13B', 'meditron-7b']\n",
    "generalist_models_l = ['Llama-2-70b-hf', 'Llama-2-70b-hf', 'Meta-Llama-3-8B-Instruct', 'Meta-Llama-3-70B-Instruct', 'Llama-2-13b-chat-hf']\n",
    "medical_models_l = ['meditron-70b', 'ClinicalCamel-70B', 'Llama3-Med42-8B', 'Llama3-Med42-70B', 'MentaLLaMA-chat-13B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "competencies = ['Overall', 'core counseling attributes', 'counseling skills and interventions', 'intake, assessment, and diagnosis', 'professional practice and ethics', 'treatment planning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "Overall\n",
      "[0.4488000000000001, 0.3208999999999999, 0.4097, 0.6214999999999999, 0.6507999999999999, 0.6507999999999999, 0.7339, 0.6507999999999999, 0.7339, 0.5386, 0.3208999999999999]\n",
      "[0.3839000000000001, 0.2303, 0.3046, 0.5931, 0.6392000000000001, 0.3710000000000001, 0.7003, 0.5759, 0.7249999999999999, 0.4760999999999999, 0.2405]\n",
      "TtestResult(statistic=3.398470105270606, pvalue=0.0067885013409609545, df=10)\n",
      "#######################\n",
      "core counseling attributes\n",
      "[0.3505999999999999, 0.4800999999999999, 0.6522, 0.4285, 0.6607999999999999, 0.6607999999999999, 0.6975000000000002, 0.6607999999999999, 0.6975000000000002, 0.4772, 0.4800999999999999]\n",
      "[0.5381, 0.2634999999999999, 0.3527, 0.5604, 0.5702, 0.3896, 0.6123999999999999, 0.4276, 0.61, 0.5229, 0.2649]\n",
      "TtestResult(statistic=2.073769173353322, pvalue=0.06487241623955775, df=10)\n",
      "#######################\n",
      "counseling skills and interventions\n",
      "[0.4393000000000001, 0.3253999999999999, 0.4251, 0.6143, 0.6624000000000001, 0.6624000000000001, 0.741, 0.6624000000000001, 0.741, 0.5139, 0.3253999999999999]\n",
      "[0.3754, 0.2238, 0.3163999999999999, 0.5718000000000001, 0.6535, 0.3656, 0.7047, 0.5959, 0.7297, 0.4501, 0.2069]\n",
      "TtestResult(statistic=3.4783102203883507, pvalue=0.005937960204147113, df=10)\n",
      "#######################\n",
      "intake, assessment, and diagnosis\n",
      "[0.4364, 0.3433, 0.4216000000000001, 0.6413000000000001, 0.6342999999999999, 0.6342999999999999, 0.7439, 0.6342999999999999, 0.7439, 0.5629000000000001, 0.3433]\n",
      "[0.3987, 0.2168, 0.2938, 0.6255, 0.6314, 0.363, 0.722, 0.5855, 0.7341, 0.4842, 0.2695]\n",
      "TtestResult(statistic=3.125052056577191, pvalue=0.010780880533986719, df=10)\n",
      "#######################\n",
      "professional practice and ethics\n",
      "[0.4367999999999999, 0.326, 0.3691, 0.6122, 0.6189999999999999, 0.6189999999999999, 0.6918999999999998, 0.6189999999999999, 0.6918999999999998, 0.5356000000000001, 0.326]\n",
      "[0.3554, 0.2593999999999999, 0.3422, 0.5727, 0.6145, 0.3014, 0.6922999999999999, 0.5361, 0.7045000000000003, 0.4518999999999999, 0.2452]\n",
      "TtestResult(statistic=2.5862070025261676, pvalue=0.02712590953790935, df=10)\n",
      "#######################\n",
      "treatment planning\n",
      "[0.5012000000000002, 0.3151, 0.4305, 0.6351, 0.6478999999999999, 0.6478999999999999, 0.7190000000000001, 0.6478999999999999, 0.7190000000000001, 0.5578, 0.3151]\n",
      "[0.3758999999999999, 0.2189, 0.3072000000000001, 0.6285000000000001, 0.6587, 0.3944, 0.7011, 0.6073000000000001, 0.7377000000000001, 0.5265000000000001, 0.2197]\n",
      "TtestResult(statistic=2.857987905690784, pvalue=0.017015485159650123, df=10)\n"
     ]
    }
   ],
   "source": [
    "mode = 'few-shot_None_3'\n",
    "pvalues = []\n",
    "for comp in competencies:\n",
    "    print('#######################')\n",
    "    print(comp)\n",
    "    generalist_f1 = []\n",
    "    medical_f1 = []\n",
    "    for model in generalist_models:\n",
    "        full_setting = model + \"_\" + mode\n",
    "        # print(full_setting)\n",
    "        generalist_f1.append(df[df['setting'] == full_setting].iloc[0][f'Accuracy_{comp}'])\n",
    "        # print(df[df['setting'] == full_setting].iloc[0]['Accuracy_counseling skills and interventions'])\n",
    "    for model in medical_models:\n",
    "        full_setting = model + \"_\" + mode\n",
    "        # print(full_setting)\n",
    "        medical_f1.append(df[df['setting'] == full_setting].iloc[0][f'Accuracy_{comp}'])\n",
    "        # print(df[df['setting'] == full_setting].iloc[0]['Accuracy_counseling skills and interventions'])\n",
    "    print(generalist_f1)\n",
    "    print(medical_f1)\n",
    "    pval = ss.ttest_rel(generalist_f1, medical_f1)\n",
    "    print(pval)\n",
    "    pvalues.append(pval.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0203655 , 0.06487242, 0.0203655 , 0.02156176, 0.03255109,\n",
       "       0.02552323])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.false_discovery_control(pvalues, method='bh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalist_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medical_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
