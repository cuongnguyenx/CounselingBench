setting,Accuracy_Overall,F1_Overall,Precision_Overall,Recall_Overall
BioMedGPT-LM-7B_zero-shot_None_0,0.4091,0.3741626600797747,0.4524834606707544,0.4007233194369419
Llama3-Med42-70B_zero-shot_None_0,0.6869,0.6497924192284158,0.6583617878881333,0.6540276027873708
Llama3-OpenBioLLM-8B_zero-shot_None_0,0.5626000000000001,0.5573287958477728,0.5634278950685374,0.560922130672891
MentaLLaMA-chat-13B_zero-shot_None_0,0.4891999999999999,0.4685830926635747,0.5491586831052304,0.4889268487196131
Llama3-Med42-8B_zero-shot_None_0,0.6264,0.6202150029845558,0.626869808882163,0.6250979887300027
Meta-Llama-3-8B-Instruct_zero-shot_None_0,0.6351,0.6297961306032865,0.6363632532221378,0.6335990670362643
ClinicalCamel-70B_zero-shot_None_0,0.6305999999999999,0.6251120374981968,0.6341405009138229,0.6284541370434006
Asclepius-7B_zero-shot_None_0,0.2848,0.274904461423906,0.2875051270957638,0.2833626582913247
Llama-2-7b-hf_zero-shot_None_0,0.4155,0.391757342502831,0.4444579601741313,0.4094011203437667
Asclepius-13B_zero-shot_None_0,0.3328,0.3191030960283371,0.3467281610405772,0.3385866695101739
Asclepius-Llama3-8B_zero-shot_None_0,0.3475999999999999,0.3332219012142217,0.3647228535887067,0.3516964961081861
meditron-7b_zero-shot_None_0,0.2529,0.2046828274867284,0.2301295953181991,0.20099293709446
Llama3-OpenBioLLM-70B_zero-shot_None_0,0.6938000000000001,0.6881574613784749,0.6957193129972269,0.6920067236645429
Llama-2-13b-hf_zero-shot_None_0,0.4513999999999999,0.4457405038344133,0.4802883659974684,0.4538092786501918
Llama-2-70b-hf_zero-shot_None_0,0.6063000000000001,0.5961388232093463,0.6028414709631934,0.6019491233926995
meditron-70b_zero-shot_None_0,0.5665,0.5534422092682146,0.5729465070087386,0.5621991485264335
Mistral-7B-Instruct-v0.3_zero-shot_None_0,0.5819000000000001,0.5753061308773362,0.5859105545351582,0.5800571194566085
med42-70b_zero-shot_None_0,0.6865000000000001,0.6809923955067153,0.687726635618666,0.6860642957308102
llama-2-7b-chat-hf_zero-shot_None_0,0.4245999999999999,0.3994804164267089,0.4547889368594102,0.418723422986827
Meta-Llama-3-70B-Instruct_zero-shot_None_0,0.7142000000000001,0.703618391660937,0.710037733417884,0.7082345209188758
medalpaca-13b_zero-shot_None_0,0.525,0.5091745742410702,0.5180389507844264,0.5141077015308657
Llama-2-13b-chat-hf_zero-shot_None_0,0.5229,0.5052897836325081,0.5571931608593186,0.5177479801414496
Llama-2-70b-chat-hf_zero-shot_None_0,0.6159,0.6065199914991491,0.6193692843962156,0.6130787884493452
counselingQA-gpt4o_zero-shot_None_0,0.7723,0.7670671986964547,0.7717857858162861,0.7704082830659215
medalpaca-7b_zero-shot_None_0,0.4103,0.4050911166339263,0.4262117356089963,0.4136898522522291
